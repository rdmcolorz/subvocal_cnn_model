{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backend_bases import RendererBase\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "#import soundfile as sf\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance\n",
    "from scipy.fftpack import fft\n",
    "from scipy.misc import imresize\n",
    "from IPython.core.display import HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import operator\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow_hub as hub\n",
    "import librosa\n",
    "from tensorflow.python.data import Dataset\n",
    "%matplotlib inline\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go', 'right', 'on', 'stop', 'left', 'off', 'yes', 'down', 'up']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_path = './data/no_vocal/'\n",
    "pic_path = \"./data/all_data/\"\n",
    "data_labels = os.listdir(audio_path)\n",
    "data_labels.pop(2)\n",
    "data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, _, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False,\n",
    "                                    nfft=1024)\n",
    "    return freqs, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wav2img(wav_path, targetdir='', figsize=(4,4)):\n",
    "    samplerate, test_sound  = wavfile.read(wav_path)\n",
    "    _, spectrogram = log_specgram(test_sound, samplerate)\n",
    "    spectrogram = imresize(spectrogram, (96,96))\n",
    "    \n",
    "    output_file = wav_path.split('/')[-1].split('.wav')[0]\n",
    "    output_file = targetdir +'/'+ output_file\n",
    "    #plt.imshow(spectrogram.T, aspect='auto', origin='lower')\n",
    "    plt.imsave('%s.jpg' % output_file, spectrogram)\n",
    "    plt.close()\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ca20e6d2a53f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchannel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mch_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"ch\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mch_sample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "# sample = []\n",
    "# for label in labels:\n",
    "#     for channel in range(1,4):\n",
    "#         ch_sample = os.listdir(audio_path + label + \"/\" + \"ch\" + str(channel))[:1]\n",
    "#         for x in ch_sample:\n",
    "#             sample.append(audio_path + label + \"/\" + \"ch\" + str(channel) + \"/\" + x)\n",
    "\n",
    "# sample\n",
    "# len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample_audio = sample\n",
    "# for i, filepath in enumerate(sample_audio[:3]):\n",
    "#     # Make subplots\n",
    "#     plt.subplot(1,3,i+1)\n",
    "#     # pull the labels\n",
    "#     plt.title(i)\n",
    "\n",
    "#     # create spectogram\n",
    "#     samplerate, test_sound  = wavfile.read(filepath)\n",
    "#     _, spectrogram = log_specgram(test_sound, samplerate)\n",
    "\n",
    "#     plt.imshow(spectrogram.T, aspect=\"auto\", origin='lower')\n",
    "#     plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i, filepath in enumerate(sample_audio[3:6]):\n",
    "#     # Make subplots\n",
    "#     plt.subplot(1,3,i+1)\n",
    "#     # pull the labels\n",
    "#     plt.title(i)\n",
    "\n",
    "#     # create spectogram\n",
    "#     samplerate, test_sound  = wavfile.read(filepath)\n",
    "#     _, spectrogram = log_specgram(test_sound, samplerate)\n",
    "\n",
    "#     plt.imshow(spectrogram.T, aspect=\"auto\", origin='lower')\n",
    "#     plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# for i, filepath in enumerate(sample_audio[6:9]):\n",
    "#     # Make subplots\n",
    "#     plt.subplot(1,3,i+1)\n",
    "#     # pull the labels\n",
    "#     plt.title(i)\n",
    "\n",
    "#     # create spectogram\n",
    "#     samplerate, test_sound  = wavfile.read(filepath)\n",
    "#     _, spectrogram = log_specgram(test_sound, samplerate)\n",
    "\n",
    "#     plt.imshow(spectrogram.T, aspect=\"auto\", origin='lower')\n",
    "#     plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_to_keep = ['yes', 'no', 'up', 'down', 'left',\n",
    "                  'right', 'on', 'off', 'stop', 'go']\n",
    "\n",
    "test_labels = ['yes', 'no', 'up', 'down', 'left',\n",
    "                  'right', 'on', 'off', 'stop', 'go', 'silence']\n",
    "\n",
    "label_dict = {'yes':0, 'no':1,'stop':2}\n",
    "\n",
    "reverse_dict = {v: k for k, v in label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i, x in enumerate(labels):\n",
    "#         all_files = [y for y in os.listdir(audio_path + x) if '.wav' in y]\n",
    "#         for file in all_files[:]:\n",
    "#             wav2img(audio_path + x + '/' + file, './data/img/' + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the pict data directory with label folders\n",
    "\n",
    "data = \"./data/\"\n",
    "labels = ['go', 'right', 'no', 'on', 'stop', 'left', 'off', 'yes', 'down', 'up']\n",
    "for f in labels:\n",
    "    if not os.path.exists(\"./data/all_data/\" + f): \n",
    "        os.mkdir(\"./data/all_data/\" + f)\n",
    "    for i in range(1,9):\n",
    "        if not os.path.exists(\"./data/all_data/\" + f + \"/\" + \"ch\" + str(i)):\n",
    "            os.mkdir(\"./data/all_data/\" + f + \"/\" + \"ch\" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : yes\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-a6285e61f40e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'204'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'205'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'197'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mwav2img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"ch\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"ch\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-e1a64d7e36b6>\u001b[0m in \u001b[0;36mwav2img\u001b[0;34m(wav_path, targetdir, figsize)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwav2img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msamplerate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sound\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mwavfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspectrogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_specgram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplerate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mspectrogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspectrogram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e7228ac1e13a>\u001b[0m in \u001b[0;36mlog_specgram\u001b[0;34m(audio, sample_rate, window_size, step_size, eps)\u001b[0m\n\u001b[1;32m      9\u001b[0m                                     \u001b[0mnoverlap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoverlap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                     \u001b[0mdetrend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                     nfft=1024)\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rainbowww5/anaconda3/lib/python3.5/site-packages/scipy/signal/spectral.py\u001b[0m in \u001b[0;36mspectrogram\u001b[0;34m(x, fs, window, nperseg, noverlap, nfft, detrend, return_onesided, scaling, axis, mode)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;31m# need to set default for nperseg before setting default for noverlap below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     window, nperseg = _triage_segments(window, nperseg,\n\u001b[0;32m--> 549\u001b[0;31m                                        input_length=x.shape[axis])\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;31m# Less overlap than welch, so samples are more statisically independent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rainbowww5/anaconda3/lib/python3.5/site-packages/scipy/signal/spectral.py\u001b[0m in \u001b[0;36m_triage_segments\u001b[0;34m(window, nperseg, input_length)\u001b[0m\n\u001b[1;32m   1637\u001b[0m                               .format(nperseg, input_length))\n\u001b[1;32m   1638\u001b[0m             \u001b[0mnperseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m         \u001b[0mwin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnperseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1640\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \u001b[0mwin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rainbowww5/anaconda3/lib/python3.5/site-packages/scipy/signal/windows.py\u001b[0m in \u001b[0;36mget_window\u001b[0;34m(window, Nx, fftbins)\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msym\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwinfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/rainbowww5/anaconda3/lib/python3.5/site-packages/scipy/signal/windows.py\u001b[0m in \u001b[0;36mhann\u001b[0;34m(M, sym)\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_trunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msym\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cos_win\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_truncate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_trunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rainbowww5/anaconda3/lib/python3.5/site-packages/scipy/signal/windows.py\u001b[0m in \u001b[0;36m_cos_win\u001b[0;34m(M, a, sym)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_trunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msym\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mfac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rainbowww5/anaconda3/lib/python3.5/site-packages/numpy/core/function_base.py\u001b[0m in \u001b[0;36mlinspace\u001b[0;34m(start, stop, num, endpoint, retstep, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#code for turning wav files into jpg.\n",
    "for i, x in enumerate(['yes','no', 'stop']):\n",
    "    print(i, ':', x)\n",
    "    # get all the wave files\n",
    "    for i in range(1,9):\n",
    "        all_files = [y for y in os.listdir(audio_path + x + \"/\" + \"ch\" + str(i)) if '.wav' in y]\n",
    "        for file in all_files:\n",
    "            if not any(x in file for x in ['204', '205', '197']):\n",
    "                wav2img(audio_path + x + \"/\" + \"ch\" + str(i) + '/' + file, pic_path + x + \"/\" + \"ch\" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i, x in enumerate(subFolderList):\n",
    "#     if x in labels_to_keep:\n",
    "#         print(i, ':', x)\n",
    "#         # get all the wave files\n",
    "#         all_files = [y for y in os.listdir(audio_path + x) if '.wav' in y]\n",
    "#         for file in all_files[101:120]:\n",
    "#             wav2img(audio_path + x + '/' + file, test_pict_Path + x)\n",
    "#     else:\n",
    "#         all_files = [y for y in os.listdir(audio_path + x) if '.wav' in y]\n",
    "#         for file in all_files[16:20]:\n",
    "#             wav2img(audio_path + x + '/' + file, \"./input/picts/test/unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test = tf.image.decode_png(\"./input/picts/train/down/00b01445_nohash_1.png\",3)\n",
    "# sess = tf.Session()\n",
    "# print(sess.run(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5825, 96, 96, 3)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "for i, x in enumerate(['yes','no', 'stop']): #choose the classes to train\n",
    "    all_files = [y for y in os.listdir(pic_path + x + \"/ch1\") if '.jpg' in y]\n",
    "    for file in all_files:\n",
    "        train_images.append(cv2.imread(pic_path + x + '/ch1/' + file))\n",
    "        train_labels.append(label_dict[x])\n",
    "\n",
    "train_images = np.array(train_images, dtype=\"float32\")\n",
    "train_images /= 255\n",
    "train_labels = np.array(train_labels)\n",
    "print(train_images.shape)\n",
    "print(type(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5825,)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 2 2 2]\n",
      "[1 1 2 ..., 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "# code to shuffe feature and label arrays.\n",
    "#train_labels.reshape((1, -1))\n",
    "train_labels = np.array(train_labels, dtype=\"int32\")\n",
    "randomize = np.arange(len(train_labels))\n",
    "np.random.shuffle(randomize)\n",
    "print(train_labels)\n",
    "labels = train_labels[randomize]\n",
    "features = train_images[randomize]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5825\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 ..., 2 2 2]\n",
      "[2 2 0 ..., 0 2 2]\n",
      "(4660,)\n",
      "(1165,)\n",
      "[[[[ 0.01176471  0.01176471  0.01176471]\n",
      "   [ 0.23921569  0.23921569  0.23921569]\n",
      "   [ 0.67843139  0.67843139  0.67843139]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.04705882  0.04705882  0.04705882]\n",
      "   [ 0.25098041  0.25098041  0.25098041]\n",
      "   [ 0.71372551  0.71372551  0.71372551]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.04313726  0.04313726  0.04313726]\n",
      "   [ 0.26666668  0.26666668  0.26666668]\n",
      "   [ 0.72941178  0.72941178  0.72941178]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.04313726  0.04313726  0.04313726]\n",
      "   [ 0.27058825  0.27058825  0.27058825]\n",
      "   [ 0.73725492  0.73725492  0.73725492]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.00784314  0.00784314  0.00784314]\n",
      "   [ 0.24313726  0.24313726  0.24313726]\n",
      "   [ 0.69803923  0.69803923  0.69803923]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.00392157  0.00392157  0.00392157]\n",
      "   [ 0.25098041  0.25098041  0.25098041]\n",
      "   [ 0.7019608   0.7019608   0.7019608 ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.02352941  0.02352941  0.02352941]\n",
      "   [ 0.26666668  0.26666668  0.26666668]\n",
      "   [ 0.71764708  0.71764708  0.71764708]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.01176471  0.01176471  0.01176471]\n",
      "   [ 0.28235295  0.28235295  0.28235295]\n",
      "   [ 0.75294119  0.75294119  0.75294119]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.03529412  0.03529412  0.03529412]\n",
      "   [ 0.26666668  0.26666668  0.26666668]\n",
      "   [ 0.71764708  0.71764708  0.71764708]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.0627451   0.0627451   0.0627451 ]\n",
      "   [ 0.27058825  0.27058825  0.27058825]\n",
      "   [ 0.74117649  0.74117649  0.74117649]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.02352941  0.02352941  0.02352941]\n",
      "   [ 0.27843139  0.27843139  0.27843139]\n",
      "   [ 0.74901962  0.74901962  0.74901962]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.        ]\n",
      "   [ 0.25490198  0.25490198  0.25490198]\n",
      "   [ 0.69803923  0.69803923  0.69803923]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.06666667  0.06666667  0.06666667]\n",
      "   [ 0.27058825  0.27058825  0.27058825]\n",
      "   [ 0.69803923  0.69803923  0.69803923]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.01960784  0.01960784  0.01960784]\n",
      "   [ 0.27058825  0.27058825  0.27058825]\n",
      "   [ 0.72156864  0.72156864  0.72156864]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.00784314  0.00784314  0.00784314]\n",
      "   [ 0.25882354  0.25882354  0.25882354]\n",
      "   [ 0.71764708  0.71764708  0.71764708]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.          0.          0.        ]\n",
      "   [ 0.25098041  0.25098041  0.25098041]\n",
      "   [ 0.70980394  0.70980394  0.70980394]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.01960784  0.01960784  0.01960784]\n",
      "   [ 0.24313726  0.24313726  0.24313726]\n",
      "   [ 0.70980394  0.70980394  0.70980394]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.07058824  0.07058824  0.07058824]\n",
      "   [ 0.25490198  0.25490198  0.25490198]\n",
      "   [ 0.71372551  0.71372551  0.71372551]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.01176471  0.01176471  0.01176471]\n",
      "   [ 0.34901962  0.34901962  0.34901962]\n",
      "   [ 0.89411765  0.89411765  0.89411765]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.0627451   0.0627451   0.0627451 ]\n",
      "   [ 0.33725491  0.33725491  0.33725491]\n",
      "   [ 0.86274511  0.86274511  0.86274511]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.07843138  0.07843138  0.07843138]\n",
      "   [ 0.36470589  0.36470589  0.36470589]\n",
      "   [ 0.88627452  0.88627452  0.88627452]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.04705882  0.04705882  0.04705882]\n",
      "   [ 0.35294119  0.35294119  0.35294119]\n",
      "   [ 0.85490197  0.85490197  0.85490197]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.01568628  0.01568628  0.01568628]\n",
      "   [ 0.35294119  0.35294119  0.35294119]\n",
      "   [ 0.87450981  0.87450981  0.87450981]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.          0.          0.        ]\n",
      "   [ 0.32549021  0.32549021  0.32549021]\n",
      "   [ 0.8392157   0.8392157   0.8392157 ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.04705882  0.04705882  0.04705882]\n",
      "   [ 0.3137255   0.3137255   0.3137255 ]\n",
      "   [ 0.80000001  0.80000001  0.80000001]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.10588235  0.10588235  0.10588235]\n",
      "   [ 0.3137255   0.3137255   0.3137255 ]\n",
      "   [ 0.80392158  0.80392158  0.80392158]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.01960784  0.01960784  0.01960784]\n",
      "   [ 0.33725491  0.33725491  0.33725491]\n",
      "   [ 0.81960785  0.81960785  0.81960785]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.          0.          0.        ]\n",
      "   [ 0.30588236  0.30588236  0.30588236]\n",
      "   [ 0.78431374  0.78431374  0.78431374]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.01960784  0.01960784  0.01960784]\n",
      "   [ 0.3137255   0.3137255   0.3137255 ]\n",
      "   [ 0.81960785  0.81960785  0.81960785]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.13333334  0.13333334  0.13333334]\n",
      "   [ 0.3137255   0.3137255   0.3137255 ]\n",
      "   [ 0.81960785  0.81960785  0.81960785]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.18431373  0.18431373  0.18431373]\n",
      "   [ 0.34901962  0.34901962  0.34901962]\n",
      "   [ 0.72156864  0.72156864  0.72156864]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.09019608  0.09019608  0.09019608]\n",
      "   [ 0.28627452  0.28627452  0.28627452]\n",
      "   [ 0.63529414  0.63529414  0.63529414]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.04705882  0.04705882  0.04705882]\n",
      "   [ 0.26666668  0.26666668  0.26666668]\n",
      "   [ 0.66666669  0.66666669  0.66666669]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.0627451   0.0627451   0.0627451 ]\n",
      "   [ 0.27058825  0.27058825  0.27058825]\n",
      "   [ 0.72156864  0.72156864  0.72156864]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.02352941  0.02352941  0.02352941]\n",
      "   [ 0.23921569  0.23921569  0.23921569]\n",
      "   [ 0.65098041  0.65098041  0.65098041]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 0.02352941  0.02352941  0.02352941]\n",
      "   [ 0.25490198  0.25490198  0.25490198]\n",
      "   [ 0.66666669  0.66666669  0.66666669]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "# code to split training and validation data\n",
    "x = len(labels)\n",
    "x *= 0.8\n",
    "x = int(x)\n",
    "training_examples = features[:x]\n",
    "validation_examples = features[x:]\n",
    "\n",
    "training_targets = labels[:x]\n",
    "validation_targets = labels[x:]\n",
    "print(training_targets)\n",
    "print(validation_targets)\n",
    "print(training_targets.shape)\n",
    "print(validation_targets.shape)\n",
    "print(training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  input_layer = tf.reshape(features, [-1, 96, 96, 3])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2) \n",
    "\n",
    "  # Convolutional Layer #2 and Pooling Layer #2\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Dense Layer\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 36864])\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits Layer\n",
    "  logits = tf.layers.dense(inputs=dropout, units=3)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "    \n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def construct_feature_columns():\n",
    "  # There are 9216 pixels in each image.\n",
    "  return set([tf.feature_column.numeric_column('pixels', shape=9216)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_predict_input_fn(features, labels, batch_size):#, num_epochs=None, shuffle=True):\n",
    "#     print(\"predict input fn\")\n",
    "#     print(type(features))\n",
    "#     print(type(labels))\n",
    "#     print(type(batch_size))\n",
    "    predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x=features,\n",
    "        y=labels,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "    return predict_input_fn\n",
    "\n",
    "def create_training_input_fn(features, labels, batch_size):#, num_epochs=None, shuffle=True):\n",
    "#     print(\"training input fn\")\n",
    "#     print(type(features))\n",
    "#     print(type(labels))\n",
    "#     print(type(batch_size))\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x=features,\n",
    "        y=labels,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=None,\n",
    "        shuffle=True)\n",
    "    return train_input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_hub_classification_model(\n",
    "    learning_rate,\n",
    "    steps,\n",
    "    batch_size,\n",
    "    hidden_units,\n",
    "    training_examples,\n",
    "    training_targets,\n",
    "    validation_examples,\n",
    "    validation_targets):\n",
    "\n",
    "    periods = 10\n",
    "    steps_per_period = steps / periods \n",
    "#     tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "# #     logging_hook = tf.train.LoggingTensorHook(\n",
    "# #         tensors=tensors_to_log, every_n_iter=10)\n",
    "    \n",
    "    predict_training_input_fn = create_predict_input_fn(training_examples, training_targets, batch_size)\n",
    "    predict_validation_input_fn = create_predict_input_fn(validation_examples, validation_targets, batch_size)\n",
    "  \n",
    "    training_input_fn = create_training_input_fn(training_examples, training_targets, batch_size)\n",
    "    predict_training_input_fn = create_predict_input_fn(training_examples, training_targets, batch_size)\n",
    "    \n",
    "    predict_validation_input_fn = create_predict_input_fn(validation_examples, validation_targets, batch_size)\n",
    "    training_input_fn = create_training_input_fn(training_examples, training_targets, batch_size)\n",
    "  \n",
    "    feature_columns = [tf.feature_column.numeric_column('pixels', shape=9216)]\n",
    "\n",
    "    my_optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "###############################################################\n",
    "    classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn,\n",
    "    model_dir=\"./mode_CNN_4\"\n",
    "    )\n",
    "##############################################################################\n",
    "    # Train the model, but do so inside a loop so that we can periodically assess\n",
    "    # loss metrics.\n",
    "    print(\"Training model...\")\n",
    "    print(\"LogLoss error (on validation data):\")\n",
    "    training_errors = []\n",
    "    validation_errors = []\n",
    "    for period in range (0, periods):\n",
    "        classifier.train(\n",
    "            input_fn=training_input_fn,\n",
    "            steps=steps_per_period,\n",
    "        )\n",
    "        training_predictions = list(classifier.predict(input_fn=predict_training_input_fn))\n",
    "        training_probabilities = np.array([item['probabilities'] for item in training_predictions])\n",
    "        training_pred_class_id = np.array([item['classes'] for item in training_predictions])\n",
    "        training_pred_one_hot = tf.keras.utils.to_categorical(training_pred_class_id,3) #change class number\n",
    "\n",
    "        validation_predictions = list(classifier.predict(input_fn=predict_validation_input_fn))\n",
    "        validation_probabilities = np.array([item['probabilities'] for item in validation_predictions])    \n",
    "        validation_pred_class_id = np.array([item['classes'] for item in validation_predictions])\n",
    "        validation_pred_one_hot = tf.keras.utils.to_categorical(validation_pred_class_id,3) #change class number\n",
    "\n",
    "        # Compute training and validation errors.\n",
    "        training_log_loss = metrics.log_loss(training_targets, training_pred_one_hot)\n",
    "        validation_log_loss = metrics.log_loss(validation_targets, validation_pred_one_hot)\n",
    "        # Occasionally print the current loss.\n",
    "        print(\"  period %02d : %0.2f\" % (period, validation_log_loss))\n",
    "        # Add the loss metrics from this period to our list.\n",
    "        training_errors.append(training_log_loss)\n",
    "        validation_errors.append(validation_log_loss)\n",
    "        \n",
    "    print(\"Model training finished.\")\n",
    "    # Remove event files to save disk space.\n",
    "    _ = map(os.remove, glob.glob(os.path.join(classifier.model_dir, 'events.out.tfevents*')))\n",
    "\n",
    "    # Calculate final predictions (not probabilities, as above).\n",
    "    final_predictions = classifier.predict(input_fn=predict_validation_input_fn)\n",
    "    final_predictions = np.array([item['classes'] for item in final_predictions])\n",
    "\n",
    "\n",
    "    accuracy = metrics.accuracy_score(validation_targets, final_predictions)\n",
    "    print(\"Final accuracy (on validation data): %0.2f\" % accuracy)\n",
    "\n",
    "    # Output a graph of loss metrics over periods.\n",
    "    plt.ylabel(\"LogLoss\")\n",
    "    plt.xlabel(\"Periods\")\n",
    "    plt.title(\"LogLoss vs. Periods\")\n",
    "    plt.plot(training_errors, label=\"training\")\n",
    "    plt.plot(validation_errors, label=\"validation\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Output a plot of the confusion matrix.\n",
    "    cm = metrics.confusion_matrix(validation_targets, final_predictions)\n",
    "    # Normalize the confusion matrix by row (i.e by the number of samples\n",
    "    # in each class).\n",
    "    cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "    ax = sns.heatmap(cm_normalized, cmap=\"bone_r\")\n",
    "    ax.set_aspect(1)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.show()\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1165, 96, 96, 3)\n",
      "1165\n"
     ]
    }
   ],
   "source": [
    "#len(set(training_targets))\n",
    "#validation_targets\n",
    "print(validation_examples.shape)\n",
    "print(len(validation_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(set(validation_targets)))\n",
    "print(len(set(training_targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "LogLoss error (on validation data):\n"
     ]
    }
   ],
   "source": [
    "classifier = train_hub_classification_model(\n",
    "    learning_rate=0.01,\n",
    "    steps=1000,\n",
    "    batch_size=100,\n",
    "    hidden_units=[200, 200],\n",
    "    training_examples=training_examples,\n",
    "    training_targets=training_targets,\n",
    "    validation_examples=validation_examples,\n",
    "    validation_targets=validation_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !sudo shutdown -h now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn,\n",
    "    model_dir=\"./mode_CNN_2\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_test_input_fn(features, batch_size=1, num_epochs=None):\n",
    "    raw_features = features\n",
    "    ds = Dataset.from_tensor_slices((raw_features))\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    features = ds.make_one_shot_iterator().get_next()\n",
    "    return features\n",
    "\n",
    "predict_test_input_fn = lambda: my_test_input_fn(\n",
    "    test_images,\n",
    "    num_epochs=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.jpg' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[:50000]:\n",
    "    test_images.append(cv2.imread(test_pict_path + file))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('sub_voice_' + 'x' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kernel keeps dying when running all test files, so I split it into thirds and concat the datasets afterward.\n",
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.jpg' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[50000:100000]:\n",
    "    test_images.append(cv2.imread(test_pict_path + file))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('sub_voice_' + 'y' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images = []\n",
    "fnames = []\n",
    "all_files = [y for y in os.listdir(test_pict_path) if '.jpg' in y]\n",
    "print(type(all_files))\n",
    "i = 0\n",
    "test_images = []\n",
    "fnames = []\n",
    "for file in all_files[100000:]:\n",
    "    test_images.append(cv2.imread(test_pict_path + file))\n",
    "    fnames.append(file[:-4] + '.wav')\n",
    "test_images = np.array(test_images, dtype=\"float32\")\n",
    "test_images /= 255\n",
    "test_predictions = classifier.predict(input_fn=predict_test_input_fn)\n",
    "test_predictions = np.array([item['classes'] for item in test_predictions])\n",
    "\n",
    "my_submission = pd.DataFrame({'fname': fnames, 'label': test_predictions})\n",
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('sub_voice_' + 'z' + '.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d0 = pd.read_csv(\"./sub_voice_\" + 'x' + \".csv\",sep=\",\")\n",
    "d1 = pd.read_csv(\"./sub_voice_\" + 'y' + \".csv\",sep=\",\")\n",
    "d2 = pd.read_csv(\"./sub_voice_\" + 'z' + \".csv\",sep=\",\")\n",
    "\n",
    "df = [d0,d1,d2]\n",
    "dx = pd.concat(df)\n",
    "\n",
    "dx = dx.replace({\"label\": reverse_dict})\n",
    "\n",
    "dx.to_csv('sub_CNN2.csv', index=False)\n",
    "dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
